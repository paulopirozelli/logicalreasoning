The Excel file contains the full set of results for the experiments described in the paper. Best results are highlighted in bold.

The file is organized according to the following tabs:
FT - Logic: Results for the hypothesis classification task [Sec. 4, Table 2]. Each of the 10 language models is fine-tuned on the 4 logical reasoning datasets (FOLIO, LogicNLI, RuleTaker, SimpleLogic), using 2 different learning rates (1e-06, 1e-05). The classifier is a 3-layer head. Number of tests: 80.
Probing - FO, Probing - LN, Probing - RT, Probing - SL: This set of tabs provides the results of the cross-probing task on the 4 different logical reasoning datasets (FOLIO, LogicNLI, RuleTaker, SimpleLogic) [Sec. 5, Table 3]. Each tab reports the scores for 5 language models (the best RoBERTa-large model for each dataset + a pretrained RoBERTa) on the specific dataset, using 5 probes (affine, 3-layers, average, weighted, lstm) and 2 learning rates (1e-06, 1e-05). Number of tests: 50 per dataset.
Layer - FO, Layer - LN, Layer - RT, Layer - SL: The tabs provide the results of the layerwise probing task on the 4 different logical reasoning datasets (FOLIO, LogicNLI, RuleTaker, SimpleLogic) [Sec. 6, Figure 2]. Each tab reports the scores for the best fine-tuned RoBERTa model on the specific dataset probed layerwise. We use 2 probes (affine, 3-layers) and 2 learning rates (1e-06, 1e-05). Number of tests: 100 per dataset.
Probing - SNLI, Probing - MultiNLI, Probing - SciTail: The tabs provide the results of the cross-probing task on the 3 NLI datasets (SNLI, MultiNLI, SciTail) [Sec. 7, Table 4]. Each tab reports the scores for 5 language models (the best RoBERTa-large model for each dataset + a pretrained RoBERTa) on the specific dataset, using 2 probes (affine, 3-layers) and 2 learning rates (1e-06, 1e-05). Number of tests: 20 per dataset.
FT - NLI: Results for the entailment task on the 3 NLI datasets (SNLI, MultiNLI, SciTail) [Sec. 7, Table 4]. A RoBERTa-large model is fine-tuned on the 3 datasets, using 2 classifiers (affine, 3-layers) and 2 learning rates (1e-06, 1e-05). Number of tests: 2 per dataset.